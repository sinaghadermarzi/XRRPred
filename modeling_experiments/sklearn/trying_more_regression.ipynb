{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas\n",
    "import itertools\n",
    "import numpy\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "from sklearn.metrics.regression import mean_absolute_error,mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "\n",
    "\n",
    "def MAE(Y1,Y2):\n",
    "    return mean_absolute_error(Y1,Y2)\n",
    "def MSE(Y1, Y2):\n",
    "    return mean_squared_error(Y1, Y2)\n",
    "def SPC(y_true, y_pred):\n",
    "    corr , _ = spearmanr(y_true,y_pred)\n",
    "    return corr\n",
    "def PNC(y_true, y_pred):\n",
    "    corr , _ = pearsonr(y_true,y_pred)\n",
    "    return corr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def normalize_df(df,features,target_col,scaler):\n",
    "    X = df.loc[:,features].values\n",
    "    Y = df.loc[:,target_col].values\n",
    "    X = scaler.transform(X)\n",
    "    out_df = pandas.DataFrame(X,index = df.index, columns=features)\n",
    "    out_df[target_col]= Y\n",
    "    return out_df\n",
    "\n",
    "\n",
    "\n",
    "def normalize_train_test(training_set_df , test_set_df, feature_cols, target_col):\n",
    "    train_set_X = training_set_df.loc[ :, feature_cols].values\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_set_X)\n",
    "    test_set_norm_df = normalize_df(test_set_df,input_features,target_col,scaler)\n",
    "    training_set_norm_df = normalize_df(training_set_df,input_features,target_col,scaler)\n",
    "    return training_set_norm_df, test_set_norm_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cross_validated_predictions(model,scorer,trainfolds_dfs,testfolds_dfs,feature_set,target_col_name):\n",
    "    y = []\n",
    "    y_pred  = []\n",
    "    scores = [None]*len(testfolds_dfs)\n",
    "    for i in range(len(testfolds_dfs)):\n",
    "        train_X = trainfolds_dfs[i].loc[:,feature_set].values\n",
    "        train_Y = trainfolds_dfs[i].loc[:,target_col_name].values\n",
    "        test_X = testfolds_dfs[i].loc[:,feature_set].values\n",
    "        test_Y = testfolds_dfs[i].loc[:,target_col_name].values\n",
    "        model.fit(train_X,train_Y)\n",
    "        test_pred = model.predict(test_X)\n",
    "        scores[i] = scorer(test_pred,test_Y)\n",
    "    # if float(\"nan\") in scores:\n",
    "    #     print(\"None seen in scores\")\n",
    "    avg_score  = numpy.mean(scores)\n",
    "    if numpy.isnan(avg_score):\n",
    "        print(\"None seen in scores\")\n",
    "    # print(\"cross validation on \",feature_set)\n",
    "    # print(\"scores: \",scores)\n",
    "    return avg_score\n",
    "\n",
    "\n",
    "\n",
    "def get_resutls_column(model,trainfolds_dfs,testfolds_dfs,train_set,test_set,feature_set,target_col_name):\n",
    "    MSEs = [None]*len(testfolds_dfs)\n",
    "    MAEs = [None]*len(testfolds_dfs)\n",
    "    SPs = [None]*len(testfolds_dfs)\n",
    "    PNs = [None]*len(testfolds_dfs)\n",
    "    for i in range(len(testfolds_dfs)):\n",
    "        train_X = trainfolds_dfs[i].loc[:,feature_set].values\n",
    "        train_Y = trainfolds_dfs[i].loc[:,target_col_name].values\n",
    "        test_X = testfolds_dfs[i].loc[:,feature_set].values\n",
    "        test_Y = testfolds_dfs[i].loc[:,target_col_name].values\n",
    "        model.fit(train_X,train_Y)\n",
    "        test_pred = model.predict(test_X)\n",
    "        MAEs[i] = MAE(test_pred,test_Y)\n",
    "        MSEs[i] = MSE(test_pred, test_Y)\n",
    "        SPs[i] = SPC(test_pred, test_Y)\n",
    "        PNs[i] = PNC(test_pred, test_Y)\n",
    "\n",
    "    train_cvavg_MAE  = numpy.mean(MAEs)\n",
    "    train_cvavg_MSE = numpy.mean(MSEs)\n",
    "    train_cvavg_PN = numpy.mean(PNs)\n",
    "    train_cvavg_SP = numpy.mean(SPs)\n",
    "\n",
    "\n",
    "    test_Y = test_set.loc[:, target_col].values\n",
    "    test_X = test_set.loc[:, feature_set].values\n",
    "    train_X = train_set.loc[:, feature_set].values\n",
    "    train_Y = train_set.loc[:, target_col].values\n",
    "\n",
    "    model.fit(train_X, train_Y)\n",
    "    test_pred = model.predict(test_X)\n",
    "\n",
    "    testset_pn, _ = pearsonr(test_Y, test_pred)\n",
    "    testset_sp, _ = spearmanr(test_Y, test_pred)\n",
    "    testset_mae = mean_absolute_error(test_Y, test_pred)\n",
    "    testset_mse = mean_squared_error(test_Y, test_pred)\n",
    "\n",
    "    column = [testset_mae, testset_mse,testset_pn, testset_sp, train_cvavg_MAE, train_cvavg_MSE, train_cvavg_PN, train_cvavg_SP ,feature_set,len(feature_set)]\n",
    "    column += list(test_pred)\n",
    "    return column\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def optimize_params(train_fold_dfs,test_fold_dfs,input_features,target_col,eval_func,tolerance,maximize,param_vals):\n",
    "    # criterions = param_vals[\"criterions\"]\n",
    "    # max_depths = param_vals[\"max_depths\"]\n",
    "    # max_featuress = param_vals[\"max_featuress\"]\n",
    "    # min_samples_splits = param_vals[\"min_samples_splits\"]\n",
    "\n",
    "    current_best_params  = None\n",
    "    current_best_score = float(\"inf\")\n",
    "    if maximize:\n",
    "        current_best_score = -current_best_score\n",
    "\n",
    "    for param_val in itertools.product(param_vals[0],param_vals[1],param_vals[2]):\n",
    "        print(\"param0= \",param_val[0])\n",
    "        print(\"param1= \", param_val[1])\n",
    "        print(\"param2= \", param_val[2])\n",
    "        print(\"\\n\")\n",
    "        # model = MLPRegressor(hidden_layer_sizes= (10,8,4,1), activation =\"relu\", alpha =param_vals[0],\n",
    "        #                      learning_rate= param_vals[1],momentum = param_vals[2])\n",
    "        model = MLPRegressor(hidden_layer_sizes= (10,8,4,1))\n",
    "        new_score = avg_cross_validation_score(model, eval_func, train_fold_dfs, test_fold_dfs,input_features, target_col)\n",
    "        print(\"score:\",new_score)\n",
    "        if maximize:\n",
    "            if new_score - current_best_score >= tolerance:\n",
    "                current_best_score = new_score\n",
    "                current_best_params = param_val\n",
    "        else:\n",
    "            if current_best_score - new_score >= tolerance:\n",
    "                current_best_score = new_score\n",
    "                current_best_params = param_val\n",
    "\n",
    "    return current_best_params\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############## read configurations\n",
    "\n",
    "import json\n",
    "with open(\"configurations.json\") as jsonfile:\n",
    "    conf = json.load(jsonfile)\n",
    "dataset_root_dir = conf[\"dataset_root_dir\"]\n",
    "sampling_methods = conf[\"sampling_methods\"]\n",
    "sampling_methods = [x+\"_lowdim\" for x in sampling_methods]\n",
    "test_set_path = dataset_root_dir + conf[\"file_locations\"][\"test_set\"]\n",
    "test_folds_relpath = conf[\"file_locations\"][\"test_folds\"]\n",
    "test_folds_path = [dataset_root_dir + relpath for relpath in test_folds_relpath]\n",
    "input_features = conf[\"input_features\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "param_pool = (\n",
    "    [None, 0.001, 0.01,0.00001],\n",
    "    [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    [0.2,0.5,None]\n",
    ")\n",
    "\n",
    "\n",
    "#####################################\n",
    "\n",
    "\n",
    "test_set_df = pandas.read_csv(test_set_path)\n",
    "num_CV_folds = len(test_folds_path)\n",
    "\n",
    "\n",
    "\n",
    "row_labels  = [\"test_MAE\",\n",
    "               \"test_MSE\",\n",
    "               \"test_pearson\",\n",
    "               \"test_spearman\",\n",
    "               \"avg_training_MAE\",\n",
    "               \"avg_test_MSE\",\n",
    "               \"avg_training_pearson\",\n",
    "               \"avg_training_spearman\",\n",
    "               \"feature_list\",\n",
    "               \"num_features\"] + list(test_set_df[\"PDB ID\"].values)\n",
    "\n",
    "\n",
    "\n",
    "for target_var in [\"resolution\",\"rfree\"]:\n",
    "    results_df = pandas.DataFrame()\n",
    "    target_col = conf[\"target_col\"][target_var]\n",
    "    input_features = conf[\"input_features\"][\"selected\"][target_var]\n",
    "    results_df[target_col] = [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"] + list(test_set_df[target_col].values)\n",
    "    for sampling in sampling_methods:\n",
    "        training_set_path = dataset_root_dir+conf[\"file_locations\"][\"training_set\"][sampling][target_var]\n",
    "        train_folds_relpath  = conf[\"file_locations\"][\"training_folds\"][sampling][target_var]\n",
    "        train_folds_path = [dataset_root_dir + relpath for relpath in train_folds_relpath]\n",
    "        test_fold_norm_df = [None] * num_CV_folds\n",
    "        train_fold_norm_df = [None] * num_CV_folds\n",
    "        for i in range(num_CV_folds):\n",
    "            train_fold_norm_df[i],test_fold_norm_df[i] = normalize_train_test(pandas.read_csv(train_folds_path[i]), pandas.read_csv(test_folds_path[i]), input_features, target_col)\n",
    "\n",
    "        train_set_norm_df, test_set_norm_df = normalize_train_test(pandas.read_csv(training_set_path),\n",
    "                                                                   pandas.read_csv(test_set_path), input_features,\n",
    "                                                                   target_col)\n",
    "\n",
    "        # best_params = optimize_params(train_fold_norm_df,test_fold_norm_df,input_features,target_col,SPC,0.005,True,param_pool)\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        # print(\"grid search done! best parameters:\")\n",
    "        # print(\"param0\", best_params[0])\n",
    "        # print(\"param1\", best_params[1])\n",
    "        # print(\"param2\", best_params[2])\n",
    "\n",
    "        model = MLPRegressor(hidden_layer_sizes= (10,8,4,1))\n",
    "        # model = MLPRegressor(hidden_layer_sizes= (10,8,4,1), activation =\"relu\", alpha =best_params[0],\n",
    "        #                      learning_rate= best_params[1],momentum = best_params[2])\n",
    "\n",
    "        results_df[\"other_\" + sampling] = get_resutls_column(model, train_fold_norm_df, test_fold_norm_df,\n",
    "                                                         train_set_norm_df, test_set_norm_df, input_features, target_col)\n",
    "\n",
    "\n",
    "    results_df.to_csv(\"results_other_\"+target_col+\"_lowdim_.csv\",columns=sorted(results_df.columns),\n",
    "                      index = row_labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
